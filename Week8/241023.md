# 오늘 배운 것
- **주요 개념**: Kubernetes 통신, 실습
- **구체적인 내용**
    - k8s 통신: 단일 노드 통신, 외부 노드와 통신, 외부 서비스간 통신
    - 실습: minikube, k3s

# 상세 학습 내용
## 쿠버네티스 컨트롤러

### Deployment

### ReplicaSet

### Job

- 하나 이상의 파드를 지정하고 지정된 수의 파드가 성공적으로 실행되도록 해주는 컨트롤러
- 하드웨어 장애나 재부팅등으로 파드가 비정상적으로 작동하면 다른 노드에서 파드를 시작해 서비스가 지속됨
- manifest

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: 잡이름
spec:
  template:
    metadata:
      name: 하나의 템플릿 이름
    spec:
      containers:
name: 컨테이너이름
image: 이미지이름
command: [명령어]
          restartPolicy: 정책	

```

### CronJob

- 특정 시간에 특정 파드를 실행시키는 기능
- 애플리케이션 프로그램 실행, 데이터베이스 백업 등의 작업을 CronJob으로 실행
- manifest
    
    ```yaml
    apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: 잡이름
    spec:
    schedule: “*/1 * * * * *” #linux의 cron 작업을 할 때 스케쥴링하는 것 과 동일	
    jobTemplate:
        metadata:
          name: 하나의 템플릿 이름
        spec:
          containers:
    name: 컨테이너이름
    image: 이미지이름
    args:
    /bin/sh
    -c
    date; echo Hello this is Cron test
              restartPolicy: 정책
    ```
    

### DaemonSet

- Deployment처럼 파드를 생성하고 관리

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: 이름
  labels:
    app: 레이블	#데몬셋을 식별할 수 있는 레이블을 설정
spec:
  selector:
    matchLabels:
      app: 앱의 레이블
  template:
    metadata:
      labels:
        app: 앱의 레이블
  spec:
    tolerations:
key: node-role/master
effect: NoSchedule

```

- taint 와 tolerations
    - 쿠버네티스 클러스터를 운영하다 보면 특정 워커 노드에는 특정 성격의 파드만 배포하고자 하는 경우가 있음
    - GPU가 설치된 파드에는 GPU가 필요한 서비스만 배포하고자 하는 경우가 대표적
    - 테인트가 설정된 노드에는 일반적으로 사용되는 파드는 배포될 수 없으나 톨러레이션을 적용하면 배포할 수 있음
    - 테인트 설정
        
        `kubectl taint node [NODE_NAME] [KEY]=[VALUE]:[EFFECT]`
        
    - EFFECT에는 3가지 옵션이 있음
        
        NoSchedule: 톨러레이션이 완전치 일치하는 파드만 배포할 수 있음
        
        NoExecute: 기존에 이미 배포된 파드를 다른 노드로 옮기고 새로운 파드는 배포하지 못하도록 하는 것
        
        PreferNoSchedule: NoSchedule 과 유사하지만 지정된 노드에는 새로운 파드가 배포되지 않지만 리소스가 부족할 때는 배포할 수 있는 차이가 있음
        

### 쿠버네티스 서비스

- 파드는 쿠버네티스 클러스터 안에서 옮겨다니는 특성이 있음
- 각각의 파드는 별도의 IP를 할당받음
- 동적으로 변하는 파드에 고정된 방법으로 접근하기 위해서 사용하는 것이 service 입니다.
- 서비스를 사용하면 파드가 클러스터 내의 어디에 떠 있든지 고정된 주소를 이용해서 접근할 수 있습니다.
- 클러스터 외부에서도 접근할 수 있습니다.
- 서비스의 종류
    - Cluster IP: 쿠버네티스 클러스터 내의 파드들은 기본적으로 외부에서 접근할 수 있는 IP를 할당받지 않지만 클러스터 내부에서는 파드들이 통신할 방법을 제공하는데 이것이 클러스터 IP 입니다.
        
        클러스터 내의 모든 파드가 해당 클러스터 IP 주소로 접근할 수 있습니다.
        
    - NodePort: 서비스를 외부로 노출할 때 사용하는 것으로 노드포트로 서비스를 노출하기 위해 워커 노드의 IP 와 포트를 이용합니다.
        
        워커 노드의 IP 가 192.168.2.3 이고 30010 포트를 사용한다면 192.168.2.3:30010 포트로 외부에서 접근 가능
        
    - Load Balancer: 로드 밸런서는 주로 퍼블릭 클라우드에 존재하는 로드 밸런서에 연결하고자 할 때 사용하는데 이 경우는 Load Balancer의 외부 IP를 통해서 접근

```yaml
apiVersion: v1
kind: Service
metadata:
  name: t-service
spec:
  selector:
    app: webserver #워커 노드에 떠 있는 컨테이너 중 webserver를 선택
 ports:
protocol: TCP
port: 80		#서비스에서 애플리케이션 과 매핑 시킬 포트번호 
targetPort: 8080  #컨테이너에서 구동 중인 애플리케이션 포트번호
```

## 쿠버네티스 통신

### 쿠버네티스 통신의 특징

- 파드가 사용하는 네트워크와 호스트(노드)가 사용하는 네트워크는 다릅니다.
    - 노드 내의 파드들은 가상의 네트워크를 사용하고 호스트는 물리 네트워크를 사용
- 같은 노드에 있는 파드끼리만 통신이 가능
    - 같은 노드에 떠 있는 파드끼리는 통신이 가능하지만 다른 노드의 파드 또는 외부와의 통신은 불가능
- 다른 노드의 파드와 통신하려면 CNI 플러그인이 필요
    - CNI(Container Network Interface)는 컨테이너 간의 통신을 위한 네트워크 인터페이스
    - CNI Plugin은 컨테이너들의 네트워크 연결하거나 삭제하면 특히 삭제할 때는 할당된 자원을 제거
        - 쿠버네티스를 설치할 때 자동`으로 구성되지 않으므로 별도로 설치해야 합니다.

### 같은 파드에 포함된 컨테이너간 통신

- Pod: docker-compose와 유사 (1개 이상의 컨테이너로 구성)
- 같은 파드 내의 컨테이너가 통신은 직접(로컬호스트 통신) 통신이 가능
- 하나의 파드에는 하나의 가상 네트워크가 만들어지고 그 파드 내에 존재하는 컨테이너들은 같은 가상 네트워크를 사용하기 때문
- 하나의 파드 내에 존재하는 컨테이너들은 모두 동일한 IP를 사용합니다.
- 하나의 파드 안에 있는 컨테이너들은 포트 번호를 이용해서 구분
- 하나의 파드가 만들어지면 가상의 네트워크가 만들어지고 브릿지가 존재하고 이 브릿지가 노드의 실제 NIC 와 연결됩니다.
    
    ![image.png](10%2023(8%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1)%20127e180c83b180aa967cd0cfb01981ae/image.png)
    

### 단일 노드에서 Pod 간 통신

- 단일 노드에 존재하는 Pod들은 같은 네트워크 대역(veth0: 172.10.0.24/24, vetho: 172.10.3/24d)에 속해있기 떄문에 통신이 가능하다.

### 여러 노드에서 Pod 간 통신

- 각 노드는 자신만의 가상 네트워크를 생성하기 때문에 다른 노드 간의 동일한 IP가 존재할 수 도 있다.
- 오버레이 네트워크를 이용해서 통신
- 오버레이 네트워크는 노드에서 사용하는 물리적인 네트워크 위에 가상의 네트워크를 구성하는 것
- 오버레이 네트워크를 사용하면 클러스터로 묶인 모든 노드에 떠 있는 파드 간의 통신이 가능합니다.
- 쿠버네티스에서는 기본적으로 kubenet이라는 기본적이고 간단한 네트워크 플러그인을 제공하는데 이 플러그인이 오버레이 네트워크를 구성합니다.

### Pod와 Service 간 통신

- Service도 Pod와 같이 IP를 할당 받지만 사용하는 대역대가 다름.
- Client 파드가 네트워크를 통해서 Web Server 파드에 http 요청을 하는 경우
    - Client 파드는 서비스 이름으로 http 요청을 보냄
    - 클러스터 DNS 서버는 서비스이름에 해당하는 서비스 IP를 Client 파드에게 전달
    - 서비스 IP를 전달받은 Client 파드는 해당 IP를 이용해서 http 요청을 보내는데 이 때 클라이언트 워커 노드는 라우팅 테이블에 서비스 IP가 있는지 검색하고 검색 결과 IP가 없으면 해당 요청을 라우터/게이트웨이 로 전달
    - 라우터 나 게이트웨이는 서비스 IP를 찾지 못할 수 있는데 이 경우 linux에 있는 netfilter 와 iptables 기능을 이용해서 찾아옵니다.
    - netfilter는 규칙 기반의 패킷 처리 엔진으로 서비스 IP를 특정 IP로 변경할 수 규칙을 저장하고 변환하는 역할을 합니다.
    
    이런 이유로 netfilter를 프록시라고 합니다.
    
    - 이 정보를 저장하고 있는 것이 iptables 입니다.

### 외부와 서비스간 통신

- NodePort: 노드 포트란 노드 IP에 포트를 붙여서 외부에 노출시키는 것
- Load Balancer: 로드 밸런서는 로드밸런서 IP를 이용해서 클러스터 외부에서 파드에 접근할 수 있도록 해주는 기능
- Ingress: 클러스터 외부에서 내부로 접근하는 요청을 어떻게 처리할 것인지에 관한 규칙의 모음이고 실제로 동작시키는 것은 Ingress Controller 입니다.
- 서비스를 넓게 이야기 할 때는 위의 3개를 포함하는 것으로 이야기 하고 좁게 이야기 할 때는 클러스터 내부에서 다른 노드에 접근할 수 있도록 해주는 것만 서비스라고 하기도 합니다.

## 실습

### k8s 실습 환경

- 운영체제 : 리눅스 (Ubuntu, Debian, Cent OS, Red Hat Enterprise, Fedora, 컨테이너 리눅스 까지 상관없음)
- 하드웨어 : CPU 2개 이상

### k8s 사용하는 포트

- Master Node 가 사용하는 포트
    - 6443: API Server
    - 2379, 2380: etcd Client API
    - 10250: kubelet API
    - 10251: Scheduler
    - 10252: Controller Manager
- Worker Node 가 사용하는 포트
    - 10250: kubelet API
    - 30000~32767: NodePort Service

### 설치 방법

**전체 설치**

- 마스터 와 워커를 다른 컴퓨터에 설치
- 가상머신을 이용해서 하나의 컴퓨터에서 마스터 와 워커 노드를 분리해서 설치

**경량 버전 설치: 운영체제 와 상관없이 설치 가능**

- k3s: 마스터 와 워커 1개씩 설정, 제약이 많음
    - https://docs.k3s.io/kr/quick-start
- minikube: 마스터 와 워커 1개씩 설정
    - https://minikube.sigs.k8s.io/docs/start/?arch=/windows/x86-64/stable/.exe+download
- kind: 마스터 1개 와 워커 여러 개 가능한데 Docker를 런타임으로 사용
- docker-desktop: 쿠버네티스 설치 옵션을 체크하면 사용 가능
- 설치 후 확인
    
    sudo kubectl run mynginx --image nginx
    
    sudo kubectl get pod
    

## 쿠버네티스 사용

### yaml

- 쿠버네티스에서는 pod를 만들 때 명령어 만으로 생성할 수 있고 yaml 파일을 생성하는 것이 가능
- 작성 요령
    - 하나의 블록에 속하는 엔트리마다 -를 붙여야 합니다.
    - 키 값 매핑은 : 으로 합니다
    - 문서의 시작 과 끝에 — 를 삽입할 수 있습니다.
    - 키 와 값 사이에 공백이 있어야 합니다.
    - 주석은 #으로 시작
    - 들여쓰기는 tab 이 아니라 공
- 검증: [https://onlineyamltools.com/validate-yaml](https://onlineyamltools.com/validate-yaml)

### 파드를 생성하고 관리

- 파드는 쿠버네티스의 기본 배포 단위이면서 다수의 컨테이너를 포함
- 일반적으로는 하나의 파드에 하나의 컨테이너가 포함되지만 하나의 컨테이너에 2개 이상의 컨테이너를 포함시킬 수 있는데 이를 sidecat pattern 이라고 합니다.
- 컨테이너 실행 : `kubectl run [ContainerName] —image [imageName]`
- 실행중인 Pod 조회 : `kubectl get pod`
    - Status
        - Pending: 생성은 되었지만 실행 되지 않은 상태
        - ContainerCreating : 생성 중
        - Running : 정상 실행 중
        - Completed: 한 번 실행하고 완료된 상태
        - Error : 에러
        - CrashLoopBackOff: 지속적인 에러 상태로 인해 crash가 반복 중
- 세부 정보 조회 : `kubectl get pod [ContainerName] -o yaml`
- 세부 정보 조회 : `kubectl get pod [ContainerName] -o wide`
- Pod 로킹 : `kubectl logs -f [podNmae]`
- pod에 명령을 수행
    
    `kubectl exec 파드이름 -- 명령`
    
    `kubectl exec mynginx -- apt-get update`
    
- 파드 내부로 들어가고자 하는 경우
    
    `kubectl exec -it 파드이름 -- bash`
    
- 파드 와 호스트간 파일 복사
    
    `kubectl cp 타겟 소스` 
    
    - 파드 안의 파일을 표현할 때 <파드이름>:>경로
    - 호스트의 /etc/password 파일을 mynginx 컨테이너의 /tml/passwr로 복사하고자 하는 경우
    
    `kubectl cp /etc/password mynginx:/tmp/passwd`
    
- 파드 정보 수정
    
    `kubectl edit pod 파드이름`
    
- 파드 삭제
    
    `kubectl delete pod 파드이름`
    

### Pod

- 쿠버네티스에서 생성하고 관리할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위
- 하나 이상의 컨테이너 그룹
- 스토리지 및 네트워크를 공유하고 함께 배치됩니다.
- Pod는 직접 생성하지 않는 경우가 많고 대부분의 경우는 워크로드 리소스를 사용해서 생성

Pod 단계

- pending: 파드가 쿠버네티스 클러스터에 승인되었지만 하나 이상의 컨테이너가 설정되지 않았고 실행할 준비가 되지 않음
    
    파드가 스케쥴되기 이전까지의 시간 뿐만 아니라 네트워크를 통한 컨테이너 이미지 다운로드 시간도 포함
    
- running : 파드가 노드에 바인딩되었고 모든 컨테이너가 생성되었으며 적어도 하나의 컨테이너가 아직 실행 중이거나 시작 또는 재시작 상태에 있는 것
- succeed : 파드에 있는 모든 컨테이너들이 성공적으로 종료되었고 재시작되지 않은 상태
- failed : 파드에 있는 모든 컨테이너가 종료되었고 적어도 하나 이상의 컨테이너가 실패로 종료된 경우인데 해당 컨테이너는 non-zero 상태로 빠져나왔거나(exit) 시스템에서 의해서 종료된 것(terminated)
- unknown : 파드에 상태를 얻을 수 없는 상태

- 컨테이너 재시작 정책 : restartPolicy
    - Always : 항상 재시작
    - OnFailure : 실패 후 재시작
    - Never : 재시작 하지 않음
    
    동일한 노드에서 kubelet에 의한 컨테이너 재시작 정책으로 파드 컨테이너에 문제가 발생해서 종료되는 경우 5분 동안 지수 백오프 지연(10, 20 ,40, 80초 —-)으로 컨테이너 재시작
    

### Pod 생성

- kubectl create 나 kubectl apply 명령으로 생성
    - httpd 이미지를 이용해서 deployment 로 파드를 생성
        
        `kubectl create deployment my-httpd --image=httpd --replicas=1 --port=80`
        
- stateless 와 stateful
    
    stateless(상태가 없음): 사용자가 애플리케이션을 사용할 때 상태나 세션을 저장할 필요가 없는 애플리케이션에 사용
    
    stateful(상태가 있음): 사용자가 애플리케이션을 사용할 때 상태나 세션을 별도의 데이터베이스에 저장해야 하는 애플리케이션에 사용
    
- deployment 를 확인
    
    `kubectl get deployment`
    
    READY: 레플리카의 개수
    
    UP-TO-DATE: 최신 상태로 업데이트 된 레플리카의 개수
    
    AVAILABLE: 사용 가능한 레플리카의 개수
    
    AGE: 파드가 실행하고 있는 지속 시간
    
- image 변경
    
    kubect set image deployment/[deploymentName] containerName=ImageName
    

## 디플로이먼트 와 서비스

### Deployment

- stateless 한 애플리케이션을 배포할 때 사용
- 레플리카 셋의 상위 개념으로 파드의 개수를 유지할 뿐 아니라 배포 작업을 좀 더 세분화해서 관리할 수 있습니다.
    
    Pod -> ReplicaSet -> Deployment
    
- 배포 전략
    - 롤링 업데이트
        - 새 버전의 애플리케이션을 배포할 때 새 버전의 애플리케이션은 하나씩 늘려가고 기존 버전의 애플리케이션은 하나씩 줄여나가는 방식
        - 쿠버네티스의 표준 배포 방식
        - 새로운 버전으로 배포된 파드에 문제가 발생하면 이전 버전의 파드로 서비스를 대체할 수 있어서 상당히 안정적이지만 업데이트가 느리게 이루어지는 단점이 있음
        - 옵션으로 maxSurge(업데이트 중에 만들 수 있는 파드의 최대 개수) 와 maxUnavailable
        - 옵션으로 maxSurge(업데이트 중에 만들 수 있는 파드의 최대 개수) 와 maxUnavailable(업데이트 중에 사용할 수 없는 파드의 개수로 0보다 큰 정수를 지정할 수 있음)
        
        ```yaml
        spec:
          replicas: 3
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxSurge: 25%
              maxUnavailable: 25%
        
        ```
        
    - recreate(재생성)
        
        이전 버전의 파드를 모두 종료하고 새 버전의 파드로 일괄 교체하는 방식
        
        빠르게 교체할 수는 있지만 새로운 버전의 파드에 문제가 발생하면 대처가 늦어질 수 있다는 단점이 있음
        
        ```yaml
        spec:
          replicas: 3
          strategy:
            type: Recreate
        ```
        
    - blue/green
        
        애플리케이션의 이전 버전(blue)와 새로운 버전(그린)이 동시에 운영되는 구조
        
        새로운 버전만 서비스 목적으로 사용 가능하고 그린은 테스트 목적
        
        새로운 버전에 문제가 있으면 바로 이전 버전으로 대체 가능하지만 파드의 개수가 늘어남
        
        ```yaml
        spec: 
          replicas: 3
          version: v1.0.0
        ```
        
    - canary
        
        블루/그린 과 비슷하지만 조금 더 진보적인 방식
        
        애플리케이션의 기능 테스트를 할 때 사용하는 방식
        
        두 개의 버전을 모두 배포하지만 새 버전에는 조금씩 트래픽을 증가(5% -> 10%... 50%)시키면서 새로운 버전의 기능을 테스트
        
        기능 테스트가 끝나고 문제가 없다고 판단되면 이전 버전은 모두 종료시키고 새 버전으로만 서비스
        
        version을 이용해서 배포