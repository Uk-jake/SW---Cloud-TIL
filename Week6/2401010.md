# 오늘 배운 것
- **주요 개념**: Cloud 아키텍처 변화, CQRS, Apache Kafka
- **구체적인 내용**
    - Cloud 아키텍처 : Monolithic, SOA, MSA
    - CQRS : 장점, 구현 이슈, 필요성
    - Apache Kafka : 역할 및 사용 이유
    - Kafka 실습

# 상세 학습 내용
# Springboot를 이용한 CQRS 구현

## MicroService & CQRS

Micro Service

- 느슨한 결합, 어느 하나의 변화가 다른 하나에 영향을 주지 않도록 서비스를 작게 만드는 것
- 서버 어플리케이션과 클라이언트 어플리케이션을 구분하며 도메인 별로 서버 어플리케이션 분리

CQRS

- 도메인 내에서도 작업에 따라 어플리케이션 구분
- 보통의 경우는 읽기와 쓰기(삽입, 삭제, 수정)을 분리
- 데이터베이스도 분리
- 읽기 작업은 NoSQL 이나 InMemory DB
- 쓰기 작업은 RDBMS를 선호

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fdf68463-1c23-421f-96a8-6b77e0a47775/a34dbbc9-4437-4b40-be46-7f14e75bb373/image.png)

## DataWrite

Dependency : Lombok, Spring Boot DevTools, Spring Web, Spring Data JPA, MySQL Driver, Kafka

## DataRead

Dependency:  Spring Boot Devtools, Lombok, Spring Web, Spring Data JPA, MySQL Driver, Spring Data MongoDB, Spring for Apache Kafka

## nginx를 이용한 Load Balancer 구현

### 1. Load Balancer 테스트를 위해서 5개의 웹 어플리케이션 생성

- flask 패키지를 설치
    
    `pip install flask`
    

### 2. nginx 설치 및 실행

**nginx**

- HTTP 기반의 서버를 생성해주는 소프트웨어
- 웹 서버를 생성할 수 있고 정적 웹페이지 호스팅 가능
- Event-Driven 구조로 동작, 고정된 프로세스 사용
- 적은 자원으로 효율적인 운용 가능
- 로드밸런싱 가능

**실행**

- brew services start nginx
- nginx의 기본 포트 80
- mac nginx 설정파일 위치 : `/opt/homebrew/etc/nginx/nginx.conf`
    - upstream과 location을 설정해주면 loadbalancing 완료
- nginx.conf
    
    ```bash
    #user  nobody;
    worker_processes  1;
    
    #error_log  logs/error.log;
    #error_log  logs/error.log  notice;
    #error_log  logs/error.log  info;
    
    #pid        logs/nginx.pid;
    
    events {
        worker_connections  1024;
    }
    
    http {
        include       mime.types;
        default_type  application/octet-stream;
    
        #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
        #                  '$status $body_bytes_sent "$http_referer" '
        #                  '"$http_user_agent" "$http_x_forwarded_for"';
    
        #access_log  logs/access.log  main;
    
        sendfile        on;
        #tcp_nopush     on;
    
        #keepalive_timeout  0;
        keepalive_timeout  65;
    
        #gzip  on;
    
        upstream backend{
    		server 127.0.0.1:5001;
    		server 127.0.0.1:5002;
    		server 127.0.0.1:5003;
    		server 127.0.0.1:5004;
    		server 127.0.0.1:5005;
        }
    
        server {
            listen       80;
            server_name  localhost;
    
            #charset koi8-r;
    
            #access_log  logs/host.access.log  main;
    
            location / {
        		proxy_pass http://backend;
            }
    
            #error_page  404              /404.html;
    
            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   html;
            }
    
            # proxy the PHP scripts to Apache listening on 127.0.0.1:80
            #
            #location ~ \.php$ {
            #    proxy_pass   http://127.0.0.1;
            #}
    
            # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
            #
            #location ~ \.php$ {
            #    root           html;
            #    fastcgi_pass   127.0.0.1:9000;
            #    fastcgi_index  index.php;
            #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
            #    include        fastcgi_params;
            #}
    
            # deny access to .htaccess files, if Apache's document root
            # concurs with nginx's one
            #
            #location ~ /\.ht {
            #    deny  all;
            #}
        }
    
        # another virtual host using mix of IP-, name-, and port-based configuration
        #
        #server {
        #    listen       8000;
        #    listen       somename:8080;
        #    server_name  somename  alias  another.alias;
    
        #    location / {
        #        root   html;
        #        index  index.html index.htm;
        #    }
        #}
    
        # HTTPS server
        #
        #server {
        #    listen       443 ssl;
        #    server_name  localhost;
    
        #    ssl_certificate      cert.pem;
        #    ssl_certificate_key  cert.key;
    
        #    ssl_session_cache    shared:SSL:1m;
        #    ssl_session_timeout  5m;
    
        #    ssl_ciphers  HIGH:!aNULL:!MD5;
        #    ssl_prefer_server_ciphers  on;
    
        #    location / {
        #        root   html;
        #        index  index.html index.htm;
        #    }
        #}
    
    }
    
    ```
    

https://velog.io/@odh0112/Nginx-HTTP-로드-밸런싱

### 3. 로드밸런싱 알고리즘

1. Round Robin
    - nginx의 기본 알고리즘 순서대로 번갈아 가면서 접속
2. Hash
    - 각 요청에 대해 사용자가 지정한 텍스트 및 NGINX 변수 조합을 기반으로 해시를 계산하고 이 해시를 서버 중 하나와 연결
    - 해당 해시가 포함된 모든 요청을 해당 서버로 전송을 하기 때문에 기본적인 종류의 세션 지속성을 설정
    - upstream을 만들 때 상단에 hash를 설정해야함.
    - 인증을 해야 이용할 수 있는 사이트 경우 Round Robin으로 만들면 접속할 때 마다 로그인을 해야할 수도 있음.
    - 고정되고 특정 서버에 접속하도록 만들고자 할 때는 Hash를 이용해야함.
3. IP_HASH
    - HTTP에서만 사용 가능한 것으로 Hash의 미리 정의된 변형으로 클라이언트의 IP주소를 기반으로 합니다.
    - ip_hash 지시문으로 설정
4. Least Connection
    - 각 서버에 대한 현재 활성화된 연결 수를 비교해서 연결이 가장 적은 서버로 요청을 전송합니다.
    - least_conn 으로 설정합니다.
    - Round Robin 이나 이 방식을 새로 고침을 하거나 브라우저 종료한 후 다시 접속하면 이전 서버에 접속한다는 보장을 못하기 때문에 세션을 유지해야 하는 서비스의 경우는 서비스를 유지할 수 있는 방법을 고려 - 메모리 데이터베이스를 이용해서 로그인을 유지하거나 맨 앞에 API Gateway를 달아서 해결
5. Least Time
    - 각 서버에 대해서 현재 활성화된 연결 수 와 과거 요청에 대한 가중 평균 응답 시간이라는 두 가지 지표를 산술적으로 계산해서 가장 낮은 값을 가진 서버로 요청을 전송
    - least_time (header | last_byte); 로 설정

### 알고리즘 선택 기준

- CPU 및 메모리 로드: 모든 서버가 동일하게 로드되지 않는다면 효율적으로 분산되지 않는 것
- 서버 응답 시간: 일부 서버의 시간이 다른 서버에 비해서 지속적으로 긴 경우 문제가 있음
- 클라이언트에 응답하는데 걸리는 총 시간
- 오류 및 요청 상태

### 알고리즘의 장 단점

1. Hash 및 IP Hash
    - 세션 지속성이 장점: 고정된 연결, A/B 테스트에 많이 사용
    - 부하를 균등하게 그리고 동일한 수로 분배한다는 보장이 없음
2. Round Robin
    - 가장 쉽게 구성이 가능
    - 서비 및 요청의 특성으로 인해서 일부 서버가 다른 서버에 비해 과부하가 걸릴 가능성이 낮을 때 사용
    - 모든 서버의 용량이 거의 동일해야 합니다.
    - 특정 파일에 대한 요청을 동일한 서버에게 보낼 수가 없기 때문에 모든 서버가 광범위한 파일을 서비스하고 캐싱하게 되어 캐시가 가득 찰 가능성이 높음
3. Least Connection 및 Least Time
    - 성능이 안정적이고 예측 가능
    - 서버의 평균 응답시간이 매우 다른 경우에 유리 → 작업 마다 시간이 다른 경우
    - 하드웨어 성능을 예측하기 어려운 클라우드 환경에서 많이 사용
    -
---

## 배운 점 & 느낀 점
- 비즈니스 민첩성의 중요성을 다시금 실감했다. 대기업들이 빠르게 변화하는 환경 속에서 새로운 기술을 도입하고 적응하는 모습을 보며, 성공적인 비즈니스를 위해서는 고객의 니즈와 기술 변화에 빠르게 대응할 수 있는 능력이 필수적이라는 점을 깨달았다. 변화하는 시장 상황에 맞춰 신속하게 대응하는 것이 기업의 생존과 발전에 결정적인 요소임을 알게 되었다.

- 이번 수업을 통해 Monolithic에서 **MSA(Microservice Architecture)**로의 변화 과정을 깊이 이해할 수 있었다. 특히 MSA로 전환할 때의 장점과 이를 통해 얻을 수 있는 유연성, 확장성에 대해 배우며, Kafka를 활용한 서비스 간 메시지 통신 방식이 매우 효율적이라는 것을 알게 되었다. 앞으로 기회가 된다면, 실제 프로젝트에서 MSA 방식을 적용하고, Kafka와 같은 메시징 시스템을 통해 다양한 서비스를 연결하고 확장해 보고 싶다.

- 또한, 그동안 개념적으로만 알고 있던 Kafka의 실질적인 사용 방법에 대해 배울 수 있었다. Kafka가 대용량 데이터를 처리하고 실시간 스트리밍을 지원하는 데 있어 얼마나 강력한 도구인지 알게 되었고, 이를 실무에서 어떻게 적용할 수 있을지 구체적으로 이해할 수 있었다. 이론뿐만 아니라 실제 사용법을 배운 것은 매우 유익한 경험이었다. 앞으로의 프로젝트에서 Kafka를 적용해 보고, 그 효용성을 더욱 깊이 탐구하고 싶다.