# 오늘 배운 것
- **주요 개념**: Cloud 아키텍처 변화, CQRS, Apache Kafka
- **구체적인 내용**
    - Cloud 아키텍처 : Monolithic, SOA, MSA
    - CQRS : 장점, 구현 이슈, 필요성
    - Apache Kafka : 역할 및 사용 이유
    - Kafka 실습

# 상세 학습 내용

## 비즈니스 민첩성

### 인터넷 기업들의 비즈니스 민첩성

- 아마존, 넷플릭스, 우버와 같은 기업들은 익숙한 비즈니스에 새로운 기술을 융합해 자신만의 특화된 서비스를 제공해 왔습니다.
- 이들 기업은 특화된 서비스를 빠르게 실행하고, 사용자 피드백을 반영하여 지속적으로 개선해 나갔습니다.
- 이들의 가장 큰 장점은 **비즈니스 민첩성**(Agility)이며, 이는 기업 성공의 핵심 요인입니다.
- **아마존**의 배포 속도:
    - 2011년, 아마존은 11.6초마다 쇼핑몰 소스코드를 변경해 배포한다고 발표했습니다.
    - 2019년에는 이 주기가 초당 1.5번으로 증가했습니다.
- 비즈니스는 지속적으로 변화하며, 이에 따라 시스템도 자주 배포되어야 합니다.
- 기업은 새로운 아이디어를 신속하게 시스템에 반영하고, 서비스 반응을 확인하여 필요 시 빠르게 시스템을 개선하고 배포해야 합니다. 따라서 배포 주기는 **비즈니스 민첩성**을 간접적으로 보여주는 중요한 지표입니다.
- **Public Cloud 인프라**의 등장으로 인해 기존 **On Premise 환경**에서처럼 인프라 준비에 많은 시간이 소요되거나 별도의 조직을 운영할 필요가 없어졌습니다. 이는 시간과 비용 절감에 큰 기여를 하고 있습니다.

### Scale Up과 Scale Out

- 성능 및 가용성을 높이는 방법으로 **Scale Up**과 **Scale Out**이 있습니다.
- **Scale Up**(수직 확장): 하드웨어의 성능을 향상시키는 방법입니다.
- **Scale Out**(수평 확장): 동일한 조건의 하드웨어 개수를 늘리는 방법입니다.
- 서버 용량을 늘릴 때:
    - **Scale Up**은 트래픽 최대치를 계산해 대용량 처리 가능한 시스템으로 업그레이드할 수 있습니다.
    - **Scale Out**은 **확장 탄력성**을 보장하며, 인스턴스를 추가하는 방식입니다.
- 특정 서비스만 탄력적으로 확장하려면, 어플리케이션을 여러 모듈로 나누어 특정 모듈만 **Scale Out**하는 것이 가능합니다.

### Cloud Friendly와 Cloud Native

- **Cloud Friendly**: 작은 단위의 서비스로 시스템을 구성하지 않고 전체 시스템을 하나로 묶어 Cloud 플랫폼에 배포하는 방식입니다. 이 방법은 배포 시 편리함을 제공합니다.
- **Cloud Native**: 독립적으로 배포할 수 있는 조각으로 구성된 어플리케이션을 **Cloud Native Application**이라고 하며, 이는 Cloud 인프라에 가장 적합하고 효과적입니다. 궁극적으로 **Cloud Friendly**에서 **Cloud Native**로의 전환이 필요합니다.

### Monolithic과 Micro Service

- **Monolithic**:
    - 하나의 단위로 개발되는 일체형 애플리케이션입니다.
    - 3-Tier 구조로 개발되며, 사용자 인터페이스(Client), 데이터베이스, 서버 어플리케이션으로 구성됩니다.
    - 서버측 어플리케이션이 논리적으로 하나의 단일체로 이루어져 있어, 확장 시 특정 기능만 확장할 수 없고 전체 어플리케이션을 동시에 확장해야 합니다.
    - 작은 변화에도 전체 어플리케이션을 다시 빌드하고 배포해야 하며, 이는 확장성에 제한을 가져옵니다.
    - 또한 데이터베이스가 통합되어 있어 탄력적으로 대응하기 어렵습니다.
- **Micro Service**:
    - 서버를 여러 개의 독립적인 조각으로 구성합니다.
    - 각 서비스는 별개의 인스턴스로 로딩되고, 각각의 저장소가 달라 모듈 경계가 명확하게 구분됩니다.
    - 각 서비스는 독립적이기 때문에 서로 다른 언어로 개발하거나, 다른 팀이 각 서비스의 개발 및 운영을 담당할 수 있습니다.

### SOA와 Micro Service

- **SOA**(Service Oriented Architecture)와 **Micro Service**는 모듈화 개념의 진화된 형태입니다. 
- **SOA**는 비즈니스적으로 완결된 서비스 단위로 모듈화된 구조를 갖는 반면, **Micro Service**는 이를 보다 구체화한 사례입니다.
- **Micro Service**는 작은 서비스들의 집합으로 구성되며, 각 서비스는 독립적인 프로세스에서 실행됩니다.
- 서비스 간 통신은 HTTP 자원 API와 같은 가벼운 수단을 사용하며, 각 서비스는 비즈니스 기능 단위로 구성되고 자동화된 배포 방식을 지원합니다.
- 중앙 집중식 관리는 최소화하고, 각 서비스는 다른 언어와 데이터 저장 기술을 사용할 수 있는 **Polyglot**한 환경을 조성할 수 있습니다.

### Micro Service를 위한 조건

1. **업무 기능 중심 팀 조직**:
   - 기존에는 UI, 서버, 데이터 등 기술별로 팀이 나뉘었지만, 마이크로 서비스 환경에서는 업무 기능 중심으로 팀을 구성해야 합니다.
   - 이 팀은 다양한 기술을 다루는 사람들이 함께 일하며 서비스를 개발하고 운영합니다. 이를 **two pizza team**이라 하여, 피자 두 판으로 나눠 먹을 수 있을 정도의 작은 규모로 팀을 구성하는 것이 이상적입니다.

2. **자율적인 분권 서비스**:
   - 중앙의 강력한 거버넌스를 추구하기보다는 각 팀이 개발과 운영을 모두 책임지고 자율적으로 서비스할 수 있는 체계가 필요합니다.
   - 서로 다른 언어와 데이터 저장 기술을 자유롭게 선택하는 **Polyglot**한 개발 환경을 구축합니다.

3. **프로젝트가 아닌 제품 중심**:
   - 소프트웨어를 단순 프로젝트가 아닌 제품으로 바라보고, 개발 후 빠르게 반응을 확인하고 개선하는 방식으로 진행합니다.

4. **인프라 자동화**:
   - 개발 환경에서 인프라를 자동화하는 것이 필수입니다. 이를 통해 개발과 배포 속도를 높일 수 있습니다.

5. **분권화된 데이터 관리**:
   - 기존 Monolithic 시스템에서는 통합된 데이터를 사용했지만, Micro Service 환경에서는 각 서비스별로 독립적인 데이터 저장소를 갖습니다.
   - 이때 다른 서비스의 데이터를 직접 호출할 수 없고, 반드시 API를 통해 접근해야 합니다. 
   - 데이터를 중앙에서 통합하지 않고 각 서비스의 저장소에 분산시킴으로써 비즈니스 일관성을 유지합니다. 이 방식은 **결과적 일관성(Eventual Consistency)**을 목표로 합니다.

6. **실패를 고려한 설계**:
   - 서비스는 장애에 대비해 설계되어야 합니다. **넷플릭스**에서는 **Chaos Monkey**라는 도구를 통해 의도적으로 장애를 발생시켜 시스템이 위기에 어떻게 대응하는지 점검합니다.

### MSA(Microservice Architecture)에 대한 이해

#### **Reactive 선언**

- **Reactive 선언**은 2014년에 발표된 현대 어플리케이션이 가져야 할 바람직한 속성들에 대한 선언으로, 아래의 4가지를 강조합니다:
  - **Responsive(응답성)**: 사용자에게 빠르고 신뢰성 있는 응답을 제공해야 합니다.
  - **Resilient(탄력성)**: 장애나 부분적인 고장에도 전체 시스템이 고장나지 않고 빠르게 복구하는 능력을 갖춰야 합니다.
  - **Elastic(유연성)**: 사용량 변화에 따라 자원을 탄력적으로 조정하며 안정적인 성능을 유지해야 합니다.
  - **Message Driven(메시지 기반)**: 비동기 메시지 전달을 통해 시스템 간의 느슨한 결합을 유지하고, 논블로킹 통신을 지원해야 합니다.

### 강한 결합에서 느슨한 결합으로의 변화

- 특정 벤더에 종속되지 않는 아키텍처를 설계하는 것이 중요합니다. 특정 벤더에 **Lock-in**되면 기술 변화에 유연하게 대처할 수 없다는 단점이 있습니다.
- 오픈 소스 기술들이 발전함에 따라 이제는 다양한 오픈 소스 제품들이 품질과 호환성 면에서 벤더 제품만큼이나 강력하게 사용될 수 있습니다. 이로 인해 특정 벤더에 의존하기보다는 오픈 소스를 사용하는 것이 권장됩니다.

---

### 구성 요소

1. **인프라 구성 요소**:
   - **Public Cloud**와 **Private Cloud**를 기반으로 구축할 수 있으며, **VM**과 **Container**를 통해 가상화를 구현합니다.
   - 컨테이너 오케스트레이션과 **CaaS**(Container as a Service)도 중요한 요소입니다.
   - AWS ECS, EKS, Google GKE와 같은 컨테이너 관리 서비스도 자주 활용됩니다.

2. **플랫폼 구성 요소**:
   - **API Gateway** 패턴을 사용해 서비스의 단일 진입점을 제공합니다.
   - **BFF(Backend for Frontend)** 패턴은 각 프론트엔드 유형에 따라 별도의 진입점을 두어 서비스를 구성하는 방식입니다.
   - **인증**과 **인가**에 대한 중앙 집중식 관리 및 클라이언트 토큰 방식, **JWT**(JSON Web Token)를 사용한 인증 방식이 포함됩니다.

3. **어플리케이션 패턴**:
   - **UI Composite Pattern**(Micro Front End)을 사용하여 여러 API를 조합한 화면을 제공합니다.
   - 동기 및 비동기 통신 방식을 구분해 사용하며, 비동기 방식에서는 **Public Cloud**의 관리형 메시징 서비스를 사용하거나 자체 구현을 결정해야 합니다.

### 어플리케이션 패턴

1. **Monolithic Front End**: 
   - 여러 API를 호출하고 조합하여 하나의 큰 화면으로 제공하는 방식입니다.
   - 프론트엔드가 하나의 큰 덩어리로 구성된 구조를 말합니다.

2. **UI Composite Pattern** (Micro Front End):
   - 메인 화면을 여러 조각으로 나누고 각 조각이 개별적인 Micro Front End로 구성됩니다.
   - 즉, 화면을 여러 작은 단위로 나누어 관리하고, 각 단위는 독립적인 마이크로 서비스를 통해 제공됩니다.

3. **통신 방식**:
   - **동기 통신**: 송신자와 수신자가 실시간으로 통신하는 방식입니다. 응답이 올 때까지 송신자는 대기합니다.
   - **비동기 통신**: 생산자와 소비자가 구분되며, 데이터를 생성하는 쪽과 소비하는 쪽이 별도로 동작하는 방식입니다. 메시지 큐 등을 통해 구독과 게시 형식으로 처리됩니다.

4. **저장소 분리 패턴**:
   - 저장소를 기능별로 분리하고, 각 서비스가 고유의 저장소를 가집니다.
   - Monolithic 구조에서는 모든 데이터가 하나의 중앙 데이터베이스에 저장되지만, Micro Service에서는 서비스별로 독립적인 데이터베이스를 사용합니다.

### 분산 트랜잭션 처리 패턴

1. **읽기와 쓰기 분리**: 
   - **CQRS**(Command Query Responsibility Segregation) 패턴을 사용해 데이터 저장소에서 읽기와 쓰기를 분리하여 성능을 최적화하고 독립적인 스케일링을 가능하게 합니다.

---

## **CQRS**

**CQRS**(Command and Query Responsibility Segregation)는 읽기와 쓰기 작업을 서로 다른 모델로 분리하여 성능, 확장성, 보안성을 높이는 패턴입니다.

### **이전 방식의 문제점**

1. **동일한 데이터 모델 사용**:
   - 기존에는 읽기와 쓰기 모두 동일한 데이터 모델을 사용했으나, 트래픽이 많을 경우 유지보수가 어려워지고 성능 저하가 발생할 수 있습니다.
   - 읽기와 쓰기는 서로 다른 성능 요구사항이 있으므로 이를 분리할 필요가 있습니다.

2. **복잡한 쿼리**:
   - 읽기 작업에서는 복잡한 쿼리가 요구되고, 쓰기 작업에서는 유효성 검사와 비즈니스 로직이 복잡해집니다.
   - 이로 인해 동일한 데이터 모델에서 이러한 작업들을 처리하기가 어려워집니다.

3. **데이터 일관성 문제**:
   - 여러 작업이 병렬로 이루어질 때 데이터 결함이 발생할 수 있습니다.

### **CQRS의 해결책**

1. **읽기와 쓰기를 분리**:
   - 읽기 작업은 읽기 전용 저장소에서, 쓰기 작업은 쓰기 전용 저장소에서 처리하여 각각의 성능을 최적화합니다.

2. **독립적인 스케일링**:
   - 쓰기 저장소와 읽기 저장소는 별도로 확장할 수 있어, 각 저장소의 트래픽에 맞춘 스케일링이 가능합니다.

3. **간단한 쿼리**:
   - 읽기 저장소는 복잡한 조인이나 ORM 매핑을 사용하지 않고 최적화된 쿼리를 사용하여 데이터를 빠르게 조회할 수 있습니다.

### **CQRS의 장점**

1. **독립적인 스케일링**: 읽기와 쓰기를 각각의 요구에 맞게 확장할 수 있습니다.
2. **최적화된 데이터 스키마**: 읽기와 쓰기 각각에 최적화된 스키마를 사용할 수 있습니다.
3. **보안성**: 읽기와 쓰기 작업을 분리함으로써 보안을 강화할 수 있습니다.
4. **간단한 쿼리**: 복잡한 데이터 조작 없이 간단한 쿼리로 데이터를 읽을 수 있습니다.

---

## **Apache Kafka**

**Kafka**는 대용량 데이터를 실시간으로 수집하고 처리하기 위한 분산 스트리밍 플랫폼입니다. 

### **Kafka의 특징**

1. **데이터 파이프라인**: 데이터 레이크와 데이터 웨어하우스 사이의 데이터를 처리하고 전송하는 파이프라인 역할을 합니다.
2. **중앙 집중화된 데이터 관리**: Kafka를 통해 여러 소스 애플리케이션에서 데이터를 중앙에 모아 저장하고 관리할 수 있습니다.
3. **고가용성**: Kafka는 클러스터로 운영되며, 장애가 발생해도 데이터를 안정적으로 처리할 수 있습니다.
4. **영속성**: 데이터는 Kafka 내부에 저장되며, 서버가 종료되더라도 데이터는 유지됩니다.
5. **확장성**: 브로커의 개수를 늘려 데이터 처리량을 조절할 수 있습니다.

### **Kafka의 구조**

1. **Producer**: 데이터를 Kafka에 보내는 역할을 합니다.
2. **Consumer**: Kafka로부터 데이터를 가져와 처리하는 역할을 합니다.
3. **Broker**: 데이터를 저장하는 역할을 하며, 클러스터로 구성되어 장애 발생 시에도 데이터를 지속적으로 처리합니다.

### **Kafka 설치 및 테스트**

1. **Docker Compose 파일 생성**: Kafka와 Zookeeper를 함께 실행하기 위한 `docker-compose.yml` 파일을 생성합니다.
2. **Kafka 설정**: Kafka의 `server.properties` 파일을 수정하여 토픽 삭제 기능을 활성화합니다.
3. **Kafka 테스트**: Kafka에서 토픽을 생성하고, 메시지를 전송 및 확인하는 명령어를 실행합니다.

---

## **Python 가상 환경**

1. **가상 환경 생성**:
   - `python3 -m venv [venv_name]` 명령어로 가상 환경을 생성합니다.
   
2. **가상 환경 활성화**:
   - `source [venv_name]/bin/activate` 명령어로 가상 환경을 활성화하여 Python 프로젝트를 실행할 수 있습니다.

---

## 배운 점 & 느낀 점
- 비즈니스 민첩성의 중요성을 다시금 실감했다. 대기업들이 빠르게 변화하는 환경 속에서 새로운 기술을 도입하고 적응하는 모습을 보며, 성공적인 비즈니스를 위해서는 고객의 니즈와 기술 변화에 빠르게 대응할 수 있는 능력이 필수적이라는 점을 깨달았다. 변화하는 시장 상황에 맞춰 신속하게 대응하는 것이 기업의 생존과 발전에 결정적인 요소임을 알게 되었다.

- 이번 수업을 통해 Monolithic에서 **MSA(Microservice Architecture)**로의 변화 과정을 깊이 이해할 수 있었다. 특히 MSA로 전환할 때의 장점과 이를 통해 얻을 수 있는 유연성, 확장성에 대해 배우며, Kafka를 활용한 서비스 간 메시지 통신 방식이 매우 효율적이라는 것을 알게 되었다. 앞으로 기회가 된다면, 실제 프로젝트에서 MSA 방식을 적용하고, Kafka와 같은 메시징 시스템을 통해 다양한 서비스를 연결하고 확장해 보고 싶다.

- 또한, 그동안 개념적으로만 알고 있던 Kafka의 실질적인 사용 방법에 대해 배울 수 있었다. Kafka가 대용량 데이터를 처리하고 실시간 스트리밍을 지원하는 데 있어 얼마나 강력한 도구인지 알게 되었고, 이를 실무에서 어떻게 적용할 수 있을지 구체적으로 이해할 수 있었다. 이론뿐만 아니라 실제 사용법을 배운 것은 매우 유익한 경험이었다. 앞으로의 프로젝트에서 Kafka를 적용해 보고, 그 효용성을 더욱 깊이 탐구하고 싶다.